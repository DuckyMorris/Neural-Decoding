{"cells":[{"metadata":{},"id":"signal-light","cell_type":"markdown","source":"# Creating Real-Time Decoding Algorithms to Understand How Neural Activity Enables Complex Behaviours"},{"metadata":{},"id":"perceived-fiber","cell_type":"markdown","source":"The field of Neuroscience is poised to enter a new era of understanding. Advances in recording technologies have given rise to an exponential increase in the amount of data that can be recorded from individual animals which opens up the possibility of gaining a much deeper understanding of how the brain enables complex behavior. However, to make sense of these new larger data sets, new data analysis methods are urgently needed. In this project, I plan to meet this need by working with Prof Ethan Meyers to develop real-time “neural decoding algorithms” that are able to convert raw neural activity into information about the sensory and behavioral stimuli that an animal is processing. In collaboration with Prof David Moorman’s lab at UMass Amherst, we plan to apply these real-time neural decoding algorithms to simultaneous recordings of large populations of neural activity in rat sensory and frontal cortex in order to predict which stimuli an animal is paying attention to."},{"metadata":{},"id":"wound-immunology","cell_type":"markdown","source":"The data analysis method I plan to develop in this project is called “neural decoding” and involves using machine learning pattern classifiers' to predict what information an animal is processing based on patterns of neural activity. In this project, I try to get this method working in simulation based on data found at http://www.readout.info/\n\nThe first step is to set up a data structure to hold the data. Below is the data structure used for this project. "},{"metadata":{"trusted":true},"id":"liable-collaboration","cell_type":"code","source":"class Data():\n    '''\n    Defined type of 3 arrays of length being the number of neurons and the length of each entry is the number of\n    samples\n    '''\n    def __init__(self):\n        self.sampled_data = []\n        self.labels = []\n        self.time_stamps = []\n    \n    def bin_data(self, bin_size, sample_rate):\n        '''\n        Calculates the average firing rates in 150 ms bins sampled every 50 ms, the following commands can be used.\n        Returns a data object but in a binned form\n        '''\n        binned = Data()\n        \n        for x in range(len(self.sampled_data)):\n            binned_array = []\n            stamps = []\n            labels = []\n            y = 0\n            while True:\n                bin = sum(self.sampled_data[x][y:y+bin_size]) / bin_size\n                binned_array.append(bin)\n                try:\n                    labels.append(self.labels[x][y])\n                except:\n                    print(x)\n                    print(y)\n                    print(len(self.labels))\n                    print(len(self.labels[x]), len(self.sampled_data[x]))\n                    exit()\n                stamps.append(y)\n                if y + sample_rate >= len(self.sampled_data[x]):\n                    break\n                else:\n                    y = y+sample_rate\n            \n            binned.sampled_data.append(binned_array)\n            binned.time_stamps.append(stamps)\n            binned.labels.append(labels)\n\n        return binned\n","execution_count":2,"outputs":[]},{"metadata":{},"id":"elect-level","cell_type":"markdown","source":"The next step is to extract the data from the folder downloaded at the link provided earlier. Below is the function that extract the data from the .mat files."},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\n!{sys.executable} -m pip install rdata","execution_count":3,"outputs":[{"output_type":"stream","text":"Requirement already satisfied: rdata in /srv/conda/envs/notebook/lib/python3.6/site-packages (0.3)\nRequirement already satisfied: pandas in /srv/conda/envs/notebook/lib/python3.6/site-packages (from rdata) (1.1.5)\nRequirement already satisfied: xarray in /srv/conda/envs/notebook/lib/python3.6/site-packages (from rdata) (0.16.2)\nRequirement already satisfied: numpy in /srv/conda/envs/notebook/lib/python3.6/site-packages (from rdata) (1.19.5)\nRequirement already satisfied: python-dateutil>=2.7.3 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from pandas->rdata) (2.8.1)\nRequirement already satisfied: pytz>=2017.2 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from pandas->rdata) (2021.1)\nRequirement already satisfied: six>=1.5 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from python-dateutil>=2.7.3->pandas->rdata) (1.15.0)\nRequirement already satisfied: setuptools>=38.4 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from xarray->rdata) (49.6.0.post20210108)\n","name":"stdout"}]},{"metadata":{"trusted":true},"id":"incomplete-input","cell_type":"code","source":"import scipy.io as sio\nimport os\nimport numpy as np\nimport pandas as pd\nimport rdata\n\ndef get_mat_data():\n    '''\n    Function that returns the data of all the matlab data in the Zhang_Desimone_7objects_raster_data folder in the form\n    of a list where each index corresponds to the data of one file\n    Each index has the following information:\n    raster_data is times from -500 to 500 and the data corresponding to these times\n    raster_labels labels contains the position and ID (type of image shown)\n    raster site info is the site info session ID, recording channel and the unit\n    '''\n    temp = os.path.join(os.getcwd(), \"Zhang_Desimone_7objects_raster_data\")\n    mat_contents = []\n    i = 1\n    for name in os.listdir(temp):\n        mat_contents.append(sio.loadmat(\"Zhang_Desimone_7objects_raster_data/\"+name))\n\n    parsed = rdata.parser.parse_file(\"ZD_150bins_50sampled.Rda\")\n    converted = rdata.conversion.convert(parsed)\n    converted = converted['binned_data']\n    return mat_contents, converted","execution_count":4,"outputs":[]},{"metadata":{},"id":"english-syntax","cell_type":"markdown","source":"Now to get the data from the files"},{"metadata":{"trusted":true},"id":"prescribed-identifier","cell_type":"code","source":"NeuralData, BinnedData = get_mat_data()","execution_count":5,"outputs":[{"output_type":"stream","text":"/srv/conda/envs/notebook/lib/python3.6/site-packages/rdata/conversion/_conversion.py:590: UserWarning: Missing constructor for R class \"binned_data\". The constructor for class \"data.frame\" will be used instead.\n  stacklevel=1)\n","name":"stderr"}]},{"metadata":{},"cell_type":"markdown","source":"The data we now have is now in raster format. Next, we need to convert this to a format to mimic that of data coming in from live probes from a rat, post spike sorting, below is the function to convert the files."},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport random\nimport sys\n\ndef random_sequence(objects, size):\n    '''\n    Function that returns a random sequence of valid objects shown to the mice where objects is the valid objects\n    that can be shown and size is the number of trials we want to try\n    '''\n    order_num = np.random.randint(0,(len(objects)),size)\n    order_objects = []\n    for x in range (size):\n        order_objects.append(objects[order_num[x]])\n\n    return order_objects\n\ndef unique(list1):\n    '''\n    Function returns unique elements in a list\n    '''\n    # intilize a null list\n    unique_list = []\n     \n    # traverse for all elements\n    for x in list1:\n        # check if exists in unique_list or not\n        if x not in unique_list:\n            unique_list.append(x)\n    return unique_list\n\n\ndef transform_raster(temp):\n    '''\n    Function takes in parameter, temp, which contains many dictories dictionaries, each extracted \n    from one .mat files containing information from one neuron.  The function converts this data into a np matrix\n    of neurons x number of samples taken (frequency x time)\n    It also respons the corresponding labels in the format 132 x 420 where each entry is a dictionary of the \n    location and type of stimulus, as well as the combined. \n    '''\n    data = []\n    labels = []\n    objects = []\n    times = []\n    for x in range(len(temp)):\n        data.append(temp[x]['raster_data'])\n        labels.append(temp[x]['raster_labels'])\n        # objects.append(labels[x][0][0][0][0][0][0])\n    #data is neurons x time x frequency, we want to now convert this to neurons x (time x frequency)\n    #labels is neurons x 1 x 1 x 3(location, type and combination) x 1 x 420 x 1. we want to transform this to neurons x (time x frequency) \n    #Here each element will be a dictionary. \n    num_trials = len(data[0])-1  # the rows in one file representing the number of trials. -1 for the 419 trial tests\n    num_neurons = len(data)\n    labels = np.array(labels)\n    for x in range (num_neurons):\n        for y in range (num_trials-1):\n            objects.append(labels[x][0][0][2][0][y][0])\n\n    objects = unique(objects) #objects is now all the unique combination of location and type of stimulus shown\n    #print(objects)\n    order = random_sequence(objects, num_trials)\n    sample = [] #sample is going to store our neurons x (time x frequency)\n    new_labels = []\n\n    for x in range (num_neurons): #number of neurons\n        time = 0\n        time_array = []\n        temp = np.array([])\n        temp_label = []\n        for y in range (len(order)): #going through the order of our pseudo population\n            valid_indexes = []\n            for z in range(num_trials):\n                if labels[x][0][0][2][0][z][0] == order[y]:\n                    valid_indexes.append(z)\n            index = random.choice(valid_indexes)\n\n            temp1 = np.array(data[x][index])\n            temp_label1 = {}\n            temp_label1['location'] = labels[x][0][0][1][0][index][0]\n            temp_label1['type'] = labels[x][0][0][0][0][index][0]\n            temp_label1['combined'] = labels[x][0][0][2][0][index][0]\n            temp_label.append(temp_label1)\n            temp = np.concatenate((temp,temp1))\n            time_array.append(time)\n            time = time + 0.001\n            time = round(time,3)\n        sample.append(temp) \n        new_labels.append(temp_label)\n        times.append(time_array)\n\n    temp = []\n    no_stimuli = {}\n    no_stimuli['location'] = \"None\"\n    no_stimuli['type'] = \"None\"\n    no_stimuli['combined'] = \"None\"\n    for x in range (len(new_labels)):\n        temp1 = []\n        for y in range (len(new_labels[x])):\n            for i in range (500):\n                temp1.append(no_stimuli)\n            for i in range (500):\n                temp1.append(new_labels[x][y])\n        temp.append(temp1)\n\n    new_labels = temp # labels is now the same dimension of sample\n    # sample = np.array(sample)\n    # times = np.array(times)\n    return sample, new_labels, times","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sampled_data, labels, timestaps = transform_raster(NeuralData) #sampled data now contains neural samples of 132 neurons, sampled at 1000Hz for 420 seconds. (132 x 420000)","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we need to place this in a data structure to something that would mimic data coming in from an Open Ephys platform: labels, and 132 channels of neural data post spike sorting. "},{"metadata":{"trusted":true},"cell_type":"code","source":"data = []\ndata.append(labels[0])\nfor x in range(len(sampled_data)):\n    data.append(sampled_data[x])","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we have the data in the format that can mimic data coming in from open ephys, and we can start our training and decoding. First, we should set up our plots. (Numbers may need adjusting due to screensize)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.ion()\nfig, axis = plt.subplots(1,2)\nax1 = axis[0]\nax2 = axis[1]\nx1=[]\ny1= []\nfor x in range(132):\n    y1.append([])\nlines = None\nprops = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\nax1.text(0.15, 0.5, \"Waiting for predicting period\" , transform=ax1.transAxes, fontsize=25, verticalalignment='top', bbox=props)\nax1.title.set_text('Bar plot showing the correlation of the current data with each class')\nax1.set_ylabel('Correlation')","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"Text(0, 0.5, 'Correlation')"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{},"cell_type":"markdown","source":"Next, we set up a loot to mimic our training phase, going through 80% of our neural data.But first, the helper functions."},{"metadata":{"trusted":true},"cell_type":"code","source":"from io import TextIOBase\nfrom numpy.core.numeric import correlate\nimport numpy as np\nimport pandas as pd\nimport datetime\nimport time\nimport pickle\nfrom sklearn.metrics import matthews_corrcoef\nimport sys\nfrom sklearn.metrics.pairwise import cosine_distances, cosine_similarity\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.animation as animation\nimport time\nfrom matplotlib.widgets import Slider\nimport matplotlib.pyplot as plt","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def grab_size(start, data, size):\n    '''\n    Function that grabs size recordings of data from matrix that is supposed to mimic that of open Ephys\n    data is the neurons array, and in this case its the raster data, start is the start column to read from \n    '''\n    result = [] #This is going to be the neurons + 1 by size array\n    for x in range(len(data)): # for each channel\n        temp = []\n        for y in range(size):\n            temp.append(data[x][y+start])\n        \n        result.append(temp)\n    return result\n\ndef add_to_trainset(train, added):\n    '''\n    train is our train set and adds added to the training set which is the labels and neurons array\n    '''\n    if train.sampled_data == []: #here our train set is un initialized\n        for x in range (len(added)-1): # set up the 132 rows\n            train.sampled_data.append(added[x+1])\n        train.labels = concatenate(train.labels, (added[0]))\n    else:\n        for x in range (len(added )-1): # go through the 132 rows \n            train.sampled_data[x] = concatenate(train.sampled_data[x], added[x+1])\n            \n        train.labels = concatenate(train.labels, (added[0]))\n    return train\n\ndef concatenate (arr1, arr2):\n    '''\n    concatenates arr2 to arr1\n    '''\n    for x in range(len(arr2)):\n        arr1.append(arr2[x])\n    \n    return arr1\n\ndef find_index(dict, label):\n    '''\n    function that finds the index of a particular label in a dictionary\n    '''\n    index = 0\n    for key in dict:\n        if key == label:\n            return index\n        else:\n            index = index+1\n\n    return -1\n\ndef update_plot1(fig,ax,cors,a,r,mse,cos):\n    for x in range (len(a)):\n        ax.clear()\n        correlations = cors[x]\n        label = a[x]\n        r_prediction = r[x]\n        mse_prediction = mse[x]\n        cos_prediction = cos[x]\n        if (label != 'pass'):\n            #print(\"label: \" + label + \"\\tr^2: \" +r_prediction + \"\\tmse: \" +mse_prediction + \"\\tcos: \" +cos_prediction)\n            keys = correlations.keys()\n            values = correlations.values()\n            #if count == 0:\n            rects = ax.bar(keys, values)\n            ax.set_ylim([0,1])\n            ax.title.set_text('Bar plot showing the correlation of the current data with each class')\n            ax.set_ylabel('Correlation')\n                    \n            for rect,h in zip(rects,values):\n                rect.set_height(h)\n                \n            if label == r_prediction:\n                rects[find_index(correlations, label)].set_color('g')\n                c1 = 'g'\n                c2 = 'g'\n            else:\n                rects[find_index(correlations, r_prediction)].set_color('r')\n                rects[find_index(correlations, label)].set_color('m')\n                c1 = 'r'\n                c2 = 'm'\n                    \n            fig.canvas.draw()\n            props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n            ax.text(0.05, 0.95, \"Actual: \"+label, transform=ax.transAxes, fontsize=14, verticalalignment='top', bbox=props)\n            ax.text(-0.7,0.93, u'\\u25CF', color = c2)\n\n            ax.text(0.05, 0.85, \"Predicted: \"+r_prediction, transform=ax.transAxes, fontsize=14, verticalalignment='top', bbox=props)\n            ax.text(-0.7,0.83, u'\\u25CF', color = c1)\n            plt.pause(0.0001)\n\n        \n        else:\n            props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n            ax.text(0.05, 0.95, \"Low correlation\", transform=ax.transAxes, fontsize=14, verticalalignment='top', bbox=props)\n\n\ndef update_plot2(fig ,num_channels, ax, x, y, lines, count, set):\n    sampled_data = set.sampled_data\n    label = set.labels[0][0]['type']\n    #print(len(x),len(y[0]))\n    x.append(count/5)\n    for i in range(num_channels):\n        y[i].append(sampled_data[i][0])\n        if len(x)>100:\n            y[i] = y[i][1:]\n    if (len(x)>100):\n        x = x[1:]\n\n    if lines == None:\n        ax.title.set_text('Graph showing the average average spike firing rate')\n        lines = {}\n        ax.set_ylim([-1,150])\n        # ax.set_yticks(range(-1, 151))\n        # ax.yaxis.set_tick_params(labelsize=5)\n        for i in range (num_channels):\n            lines[i], = ax.plot([0], [i])\n\n        ax.set_xlabel(\"Time in the experiment in seconds\")\n        ax.set_ylabel(\"Channel/Neuron number and Average Firing Rate \\n spike firing rate = (y - neuron number)/(8 * 0.2) Hz\")\n\n    for i in range(num_channels):\n        lines[i].set_xdata(x)\n        temp =  [(a + i*0.125)*8 +1 for a in y[i]] \n        lines[i].set_ydata(temp)\n\n    if len(x) == 100:\n        ax.set_xlim([min(x),max(x)])\n    else:\n        ax.set_xlim([0,20])\n\n    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n    for txt in ax.texts:\n        txt.set_visible(False)\n    ax.text(0.6, 0.95, \"Image being shown: \"+label, transform=ax.transAxes, fontsize=14, verticalalignment='top', bbox=props)\n    fig.canvas.draw()\n    fig.canvas.flush_events()\n\n    return lines,x,y\n#     # updating data values\n\ndef train(train_set):\n    '''\n    Trains our model and returns our models for our classes. Here train_set represnts our training set\n    '''\n    names = []\n    for x in range(len(train_set.labels[0])):\n        names.append(train_set.labels[0][x]['type'])\n\n    class_names = unique(names) #the 8 class names\n\n    classes = {} # this is a dictionary of the 8 classes which have arrays of the length of the number of neurons\n    zeroed = [0] * (len(train_set.sampled_data)+1) # the extra 1 indicates the number of occurences \n    for name in class_names :\n        classes[name] = np.array(zeroed)\n    #training:\n    for x in range(len(train_set.sampled_data[0])):\n        label = train_set.labels[0][x]['type']\n        #print(label)\n        neurons = []\n        for y in range(len(train_set.sampled_data)):\n            neurons.append(train_set.sampled_data[y][x])\n        neurons.append(1)\n        neurons = np.array(neurons)\n        #neuron is now of length 133, containing a column of raster data, and 1 for once occurence\n        #Now adding it to the relevant class\n        classes[label] = classes[label]+neurons \n\n\n    for key in classes :\n        array = (classes[key]/classes[key][len(classes[key])-1])\n        classes[key] = array[0:len(classes[key])-1] #Get the average over all the bins and remove the counter \n\n    return classes\n\ndef predict(test_set, classes):\n    '''\n    makes predictions for the passed in set and returns arrays of the actual labels, and the corresponding predictions\n    '''\n    correlations = []\n    actual = []\n    rpredicted = []\n    msepredicted = []\n    cospredicted = []\n\n    for x in range(len(test_set.sampled_data[0])):\n        label = test_set.labels[0][x]['type']\n        neurons = []\n        for y in range(len(test_set.sampled_data)):\n            neurons.append(test_set.sampled_data[y][x])\n        neurons = np.array(neurons)\n\n        rs = {}\n        mses = {}\n        coses ={}\n\n        for key in classes :\n            object = key\n            array = classes[key]\n            mse = ((array - neurons)**2).mean()\n            cos =cosine_similarity([array], [neurons])[0][0]\n            try :\n                r = np.corrcoef(array, neurons)[0,1]\n            except:\n                r = mse\n\n            rs[key] = r\n            mses[key] = mse\n            coses[key] = cos\n            \n        r_prediction = max(rs, key=rs.get)\n        mse_prediction = min(mses, key=mses.get)\n        cos_prediction = max(coses, key=coses.get)\n        \n        p = False\n        if (round(rs[r_prediction],2) <0.4):\n            p = True\n            actual.append('pass')\n            rpredicted.append('pass')\n            msepredicted.append('pass')\n            cospredicted.append('pass')\n        else:\n            actual.append(label)\n            msepredicted.append(mse_prediction)\n            rpredicted.append(r_prediction)\n            cospredicted.append(cos_prediction)\n\n        correlations.append(rs)\n        #print(\"label: \" + label + \"\\tr^2 \" +str(round(rs[r_prediction],2))+\": \" +r_prediction)\n\n    return actual, rpredicted, msepredicted, cospredicted, correlations","execution_count":13,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that we have the necessary functions set up, we can start the driving program"},{"metadata":{"trusted":true},"cell_type":"code","source":"index = 0\ntrain_set = Data()\ntrain_set.sampled_data = [] \ntrain_set.labels = []\nloop_counter = 0\nnum_channels = len(data)\n\nwhile index < len(data[0]) * 0.8 :\n    temp_set = Data()\n    temp = grab_size(index, data, 200) #In the open ephys, this temp would be simply the data receieved from the plugin\n    train_set = add_to_trainset(train_set,temp)#We now want to add temp to our training set \n    temp_set = add_to_trainset(temp_set,temp)\n\n    #plot\n    temp = []\n    for x in range (len(temp_set.sampled_data)):\n        temp.append(temp_set.labels)\n    temp_set.labels = temp\n    temp_set = temp_set.bin_data(200,200)\n    lines, x1 , y1 = update_plot2(fig ,num_channels-1, ax2, x1, y1,  lines, loop_counter, temp_set)\n    #\n\n    index = index + 200\n\n    if (index > len(data[0])):\n        index = 0 \n\n    t2 = datetime.datetime.now()\n    loop_counter = loop_counter +1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We now have finished collected data from the training set, now realigning our training set and bin the data to form our classes for predictions."},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = []\n\nfor x in range (len(train_set.sampled_data)):\n    temp.append(train_set.labels)\ntrain_set.labels = temp\n\n\ntrain_set = train_set.bin_data(200,200)\nclasses = train(train_set)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have finished training the data, and now we can start predicting on the last 20% of data"},{"metadata":{"trusted":true},"cell_type":"code","source":"actual = []\nrpredicted = []\nmsepredicted = []\ncospredicted = []\n\ncount = 0\n\nwhile index < len(data[0]) :\n    test_set = Data()\n    temp = grab_size(index, data, 200) \n    test_set = add_to_trainset(test_set,temp)\n\n    temp = []\n    for x in range (len(test_set.sampled_data)):\n        temp.append(test_set.labels)\n    test_set.labels = temp\n\n    test_set = test_set.bin_data(200,200)\n    a, r, mse, cos, cors = predict(test_set, classes)\n    #plots\n    update_plot1(fig,ax1,cors,a,r,mse,cos)\n    \n    lines, x1 , y1 = update_plot2(fig ,num_channels-1, ax2, x1, y1, lines, loop_counter, test_set)\n    #end plots\n    actual = concatenate(actual, a)\n    rpredicted = concatenate(rpredicted, r)\n    msepredicted = concatenate(msepredicted, mse)\n    cospredicted = concatenate(cospredicted, cos)\n\n    index = index + 200\n\n    #now we plot\n    #\n\n    time.sleep(0.1)\n    t2 = datetime.datetime.now()\n    count = count+1\n    loop_counter = loop_counter + 1\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lastly, a summary of our experiment. "},{"metadata":{"trusted":true},"cell_type":"code","source":"len1 = len(actual)\n\nactual = [value for value in actual if value != 'pass']\nrpredicted = [value for value in rpredicted if value != 'pass']\nmsepredicted = [value for value in msepredicted if value != 'pass']\ncospredicted = [value for value in cospredicted if value != 'pass']\nlen2  = len(actual)\n\nprint()\n\nprint(\"Accuracy: \", round(accuracy_score(actual, rpredicted)*100,2), \"%\", \"\\tmatthews corr coef: \", round(matthews_corrcoef(actual, rpredicted),2),\"\\tF1: \", round(f1_score(actual, rpredicted, average = 'weighted'),2), sep = \"\")\nprint()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This concludes the simulation of live time decoding. This method showed to have an constant accuaracy above 75%. The next steps would to either insert this method into the pipeline of live time analysis of neural data, or try to improve on this algorithm"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":5}